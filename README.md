
<ul>
<li><strong>Scalable Object Detection Using Deep Neural Networks</strong>&nbsp;[cvpr14]&nbsp;<a href="1/Scalable%20Object%20Detection%20Using%20Deep%20Neural%20Networks%20cvpr14.pdf">[pdf]</a>&nbsp;<a href="1/Scalable%20Object%20Detection%20Using%20Deep%20Neural%20Networks%20cvpr14.pdf">[notes]</a></li>
<li><strong>Selective Search for Object Recognition</strong>&nbsp;[ijcv2013]&nbsp;<a href="1/Selective%20Search%20for%20Object%20Recognition%20ijcv2013.pdf">[pdf]</a>&nbsp;<a href="1/Selective%20Search%20for%20Object%20Recognition%20ijcv2013.pdf">[notes]</a></li>

<li><strong>Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks</strong>&nbsp;[tpami17]&nbsp;<a href="1/Faster%20R-CNN%20Towards%20Real-Time%20Object%20Detection%20with%20Region%20Proposal%20Networks%20tpami17%20ax16_1.pdf">[pdf]</a>&nbsp;<a href="1/Faster_R-CNN.pdf">[notes]</a></li>
<li><strong>RFCN - Object Detection via Region-based Fully Convolutional Networks</strong>&nbsp;[nips16] [Microsoft Research]&nbsp;<a href="1/RFCN-Object%20Detection%20via%20Region-based%20Fully%20Convolutional%20Networks%20nips16.pdf">[pdf]</a>&nbsp;<a href="1/RFCN.pdf">[notes]</a></li>
<li><strong>Mask R-CNN</strong>&nbsp;[iccv17] [Facebook AI Research]&nbsp;<a href="1/Mask%20R-CNN%20ax17_4%20iccv17.pdf">[pdf]</a>&nbsp;<a href="1/Mask%20R-CNN%20ax17_4%20iccv17.pdf">[notes]</a>&nbsp;&nbsp;&nbsp;</li>
<li><strong>SNIPER Efficient Multi-Scale Training</strong>&nbsp;[ax1812/nips18]&nbsp;<a href="1/SNIPER%20Efficient%20Multi-Scale%20Training%20ax181213%20nips18.pdf">[pdf]</a>&nbsp;<a href="1/SNIPER%20Efficient%20Multi-Scale%20Training%20ax181213%20nips18.pdf">[notes]</a>&nbsp;</li>

<li><strong>You Only Look Once Unified, Real-Time Object Detection</strong>&nbsp;[ax1605]&nbsp;<a href="1/You%20Only%20Look%20Once%20Unified,%20Real-Time%20Object%20Detection%20ax1605.pdf">[pdf]</a>&nbsp;<a href="1/You%20Only%20Look%20Once%20Unified,%20Real-Time%20Object%20Detection%20ax1605.pdf">[notes]</a></li>
<li><strong>YOLO9000 Better, Faster, Stronger</strong>&nbsp;[ax1612]&nbsp;<a href="1/YOLO9000%20Better,%20Faster,%20Stronger%20ax16_12.pdf">[pdf]</a>&nbsp;<a href="1/YOLO9000%20Better,%20Faster,%20Stronger%20ax16_12.pdf">[notes]</a></li>
<li><strong>YOLOv3 An Incremental Improvement</strong>&nbsp;[ax1804]&nbsp;<a href="1/YOLOv3%20An%20Incremental%20Improvement%20ax180408.pdf">[pdf]</a>&nbsp;<a href="1/YOLOv3%20An%20Incremental%20Improvement%20ax180408.pdf">[notes]</a></li>
<li><strong>YOLOv4 Optimal Speed and Accuracy of Object Detection</strong>&nbsp;[ax2004]&nbsp;<a href="1/YOLOV4_Optimal%20Speed%20and%20Accuracy%20of%20Object%20Detection%20ax200423.pdf">[pdf]</a>&nbsp;<a href="1/YOLOV4_Optimal%20Speed%20and%20Accuracy%20of%20Object%20Detection%20ax200423.pdf">[notes]</a>&nbsp;</li>

<li><strong>SSD Single Shot MultiBox Detector</strong>&nbsp;[ax1612/eccv16]&nbsp;<a href="1/SSD%20Single%20Shot%20MultiBox%20Detector%20eccv16_ax16_12.pdf">[pdf]</a>&nbsp;<a href="1/SSD.pdf">[notes]</a></li>
<li><strong>DSSD Deconvolutional Single Shot Detector</strong>&nbsp;[ax1701]&nbsp;<a href="1/DSSD%20Deconvolutional%20Single%20Shot%20Detector%20ax1701.06659.pdf">[pdf]</a>&nbsp;<a href="1/DSSD.pdf">[notes]</a></li>

<li><strong>Feature Pyramid Networks for Object Detection</strong>&nbsp;[ax1704]&nbsp;<a href="1/Feature%20Pyramid%20Networks%20for%20Object%20Detection%20ax170419.pdf">[pdf]</a>&nbsp;<a href="1/FPN.pdf">[notes]</a></li>
<li><strong>Focal Loss for Dense Object Detection</strong>&nbsp;[ax180207/iccv17]&nbsp;<a href="1/Focal%20Loss%20for%20Dense%20Object%20Detection%20ax180207%20iccv17.pdf">[pdf]</a>&nbsp;<a href="1/focal_loss.pdf">[notes]</a></li>

<li><strong>FoveaBox: Beyond Anchor-based Object Detector</strong>&nbsp;[ax1904]&nbsp;<a href="1/FoveaBox%20Beyond%20Anchor-based%20Object%20Detector%20ax1904.03797.pdf">[pdf]</a>&nbsp;<a href="1/FoveaBox%20Beyond%20Anchor-based%20Object%20Detector%20ax1904.03797.pdf">[notes]</a>&nbsp;</li>
<li><strong>CornerNet: Detecting Objects as Paired Keypoints</strong>&nbsp;[ax1903/ijcv19]&nbsp;<a href="1/CornerNet%20Detecting%20Objects%20as%20Paired%20Keypoints%20ax1903%20ijcv19.pdf">[pdf]</a>&nbsp;<a href="1/CornerNet%20Detecting%20Objects%20as%20Paired%20Keypoints%20ax1903%20ijcv19.pdf">[notes]</a>&nbsp;</li>
<li><strong>FCOS Fully Convolutional One-Stage Object Detection</strong>&nbsp;[ax1908/iccv19]&nbsp;<a href="1/FCOS%20Fully%20Convolutional%20One-Stage%20Object%20Detection%20ax1908%20iccv19.pdf">[pdf]</a>&nbsp;<a href="1/FCOS%20Fully%20Convolutional%20One-Stage%20Object%20Detection%20ax1908%20iccv19.pdf">[notes]</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</li>
<li><strong>Feature Selective Anchor-Free Module for Single-Shot Object Detection</strong>&nbsp;[ax1903/cvpr19]&nbsp;<a href="1/Feature%20Selective%20Anchor-Free%20Module%20for%20Single-Shot%20Object%20Detection%20ax1903.00621%20cvpr19.pdf">[pdf]</a>&nbsp;<a href="1/Feature%20Selective%20Anchor-Free%20Module%20for%20Single-Shot%20Object%20Detection%20ax1903.00621%20cvpr19.pdf">[notes]</a>&nbsp;</li>
<li><strong>Bottom-up object detection by grouping extreme and center points</strong>&nbsp;[ax1901]&nbsp;<a href="1/Bottom-up%20object%20detection%20by%20grouping%20extreme%20and%20center%20points%201901.08043.pdf">[pdf]</a>&nbsp;<a href="1/Bottom-up%20object%20detection%20by%20grouping%20extreme%20and%20center%20points%201901.08043.pdf">[notes]</a>&nbsp;</li>
<li><strong>Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection</strong>&nbsp;[ax1912/cvpr20]&nbsp;<a href="1/Bridging%20the%20Gap%20Between%20Anchor-based%20and%20Anchor-free%20Detection%20via%20Adaptive%20Training%20Sample%20Selection%201912.02424%20cvpr20.pdf">[pdf]</a>&nbsp;<a href="1/Bridging%20the%20Gap%20Between%20Anchor-based%20and%20Anchor-free%20Detection%20via%20Adaptive%20Training%20Sample%20Selection%201912.02424%20cvpr20.pdf">[notes]</a>&nbsp;</li>

<li>
<p><strong>OverFeat Integrated Recognition, Localization and Detection using Convolutional Networks</strong>&nbsp;[ax1402/iclr14]&nbsp;<a href="1/OverFeat%20Integrated%20Recognition,%20Localization%20and%20Detection%20using%20Convolutional%20Networks%20ax1402%20iclr14.pdf">[pdf]</a>&nbsp;<a href="1/OverFeat%20Integrated%20Recognition,%20Localization%20and%20Detection%20using%20Convolutional%20Networks%20ax1402%20iclr14.pdf">[notes]</a></p>
</li>
<li>
<p><strong>LSDA Large scale detection through adaptation</strong>&nbsp;[ax1411/nips14]&nbsp;<a href="1/LSDA%20Large%20scale%20detection%20through%20adaptation%20nips14%20ax14_11.pdf">[pdf]</a>&nbsp;<a href="1/LSDA%20Large%20scale%20detection%20through%20adaptation%20nips14%20ax14_11.pdf">[notes]</a></p>
</li>
<li>
<p><strong>Acquisition of Localization Confidence for Accurate Object Detection</strong>&nbsp;[ax1807/eccv18]&nbsp;<a href="1/1.pdf">[pdf]</a>&nbsp;<a href="1/IOU-Net.pdf">[notes]</a>&nbsp;</p>
</li>
<li>
<p><strong>EfficientDet: Scalable and Efficient Object Detection</strong>&nbsp;[cvpr20]&nbsp;<a href="1/EfficientDet_Scalable%20and%20efficient%20object%20detection.pdf">[pdf]</a></p>
</li>
<li>
<p><strong>Generalized Intersection over Union A Metric and A Loss for Bounding Box Regression</strong>&nbsp;[ax1902/cvpr19]&nbsp;<a href="1/Generalized%20Intersection%20over%20Union%20A%20Metric%20and%20A%20Loss%20for%20Bounding%20Box%20Regression%201902.09630%20cvpr19.pdf">[pdf]</a>&nbsp;<a href="1/Generalized%20Intersection%20over%20Union%20A%20Metric%20and%20A%20Loss%20for%20Bounding%20Box%20Regression%201902.09630%20cvpr19.pdf">[notes]</a>&nbsp;&nbsp;</p>
</li>

<li><strong>Object Detection from Video Tubelets with Convolutional Neural Networks</strong>&nbsp;[cvpr16]&nbsp;<a href="1/Object_Detection_from_Video_Tubelets_with_Convolutional_Neural_Networks_CVPR16.pdf">[pdf]</a>&nbsp;<a href="1/Object_Detection_from_Video_Tubelets_with_Convolutional_Neural_Networks_CVPR16.pdf">[notes]</a></li>
<li><strong>Object Detection in Videos with Tubelet Proposal Networks</strong>&nbsp;[ax1704/cvpr17]&nbsp;<a href="1/Object_Detection_in_Videos_with_Tubelet_Proposal_Networks_ax1704_cvpr17.pdf">[pdf]</a>&nbsp;<a href="1/Object_Detection_in_Videos_with_Tubelet_Proposal_Networks_ax1704_cvpr17.pdf">[notes]</a></li>

<li><strong>Deep Feature Flow for Video Recognition</strong>&nbsp;[cvpr17] [Microsoft Research]&nbsp;<a href="1/Deep%20Feature%20Flow%20For%20Video%20Recognition%20cvpr17.pdf">[pdf]</a>&nbsp;&nbsp;</li>
<li><strong>Flow-Guided Feature Aggregation for Video Object Detection</strong>&nbsp;[ax1708/iccv17]&nbsp;<a href="1/Flow-Guided%20Feature%20Aggregation%20for%20Video%20Object%20Detection%20ax1708%20iccv17.pdf">[pdf]</a>&nbsp;<a href="1/Flow-Guided%20Feature%20Aggregation%20for%20Video%20Object%20Detection%20ax1708%20iccv17.pdf">[notes]</a></li>
<li><strong>Towards High Performance Video Object Detection</strong>&nbsp;[ax1711] [Microsoft]&nbsp;<a href="1/2.pdf">[pdf]</a></li>

<li><strong>Online Video Object Detection using Association LSTM</strong>&nbsp;[iccv17]&nbsp;<a href="1/Online%20Video%20Object%20Detection%20using%20Association%20LSTM%20iccv17.pdf">[pdf]</a>&nbsp;<a href="1/Online%20Video%20Object%20Detection%20using%20Association%20LSTM%20iccv17.pdf">[notes]</a></li>
<li><strong>Context Matters ReÔ¨Åning Object Detection in Video with Recurrent Neural Networks</strong>&nbsp;[bmvc16]&nbsp;<a href="1/Context%20Matters%20Re%EF%AC%81ning%20Object%20Detection%20in%20Video%20with%20Recurrent%20Neural%20Networks%20bmvc16.pdf">[pdf]</a>&nbsp;<a href="1/Context%20Matters%20Re%EF%AC%81ning%20Object%20Detection%20in%20Video%20with%20Recurrent%20Neural%20Networks%20bmvc16.pdf">[notes]</a></li>

<li><strong>Tracking Objects as Points</strong>&nbsp;[ax2004]&nbsp;<a href="1/Tracking%20Objects%20as%20Points%202004.01177.pdf">[pdf]</a>&nbsp;<a href="1/Tracking%20Objects%20as%20Points%202004.01177.pdf">[notes]</a>&nbsp;[pytorch]</li>

<li><strong>MOTS Multi-Object Tracking and Segmentation</strong>&nbsp;[cvpr19]&nbsp;<a href="1/MOTS%20Multi-Object%20Tracking%20and%20Segmentation%20ax1904%20cvpr19.pdf">[pdf]</a>&nbsp;<a href="1/MOTS%20Multi-Object%20Tracking%20and%20Segmentation%20ax1904%20cvpr19.pdf">[notes]</a>&nbsp;&nbsp;</li>
<li><strong>Towards Real-Time Multi-Object Tracking</strong>&nbsp;[ax1909]&nbsp;<a href="1/Towards%20Real-Time%20Multi-Object%20Tracking%20ax1909.12605v1.pdf">[pdf]</a>&nbsp;<a href="1/Towards%20Real-Time%20Multi-Object%20Tracking%20ax1909.12605v1.pdf">[notes]</a></li>
<li><strong>A Simple Baseline for Multi-Object Tracking</strong>&nbsp;[ax2004]&nbsp;<a href="1/A%20Simple%20Baseline%20for%20Multi-Object%20Tracking%202004.01888.pdf">[pdf]</a>&nbsp;<a href="1/A%20Simple%20Baseline%20for%20Multi-Object%20Tracking%202004.01888.pdf">[notes]</a>&nbsp;</li>

<li><strong>Deep Affinity Network for Multiple Object Tracking</strong>&nbsp;[ax1810/tpami19]&nbsp;<a href="1/Deep%20Affinity%20Network%20for%20Multiple%20Object%20Tracking%20ax1810.11780%20tpami19.pdf">[pdf]</a>&nbsp;<a href="1/Deep%20Affinity%20Network%20for%20Multiple%20Object%20Tracking%20ax1810.11780%20tpami19.pdf">[notes]</a>&nbsp;&nbsp;[pytorch]</li>

<li>
<p><strong>Online Multi-Object Tracking Using CNN-based Single Object Tracker with Spatial-Temporal Attention Mechanism</strong>&nbsp;[ax1708/iccv17]&nbsp;<a href="1/Online%20Multi-Object%20Tracking%20Using%20CNN-based%20Single%20Object%20Tracker%20with%20Spatial-Temporal%20Attention%20Mechanism%201708.02843%20iccv17.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/Online%20Multi-Object%20Tracking%20Using%20CNN-based%20Single%20Object%20Tracker%20with%20Spatial-Temporal%20Attention%20Mechanism%201708.02843%20iccv17.pdf">[notes]</a></p>
</li>
<li>
<p><strong>Online multi-object tracking with dual matching attention networks</strong>&nbsp;[ax1902/eccv18]&nbsp;<a href="1/Online%20multi-object%20tracking%20with%20dual%20matching%20attention%20networks%201902.00749%20eccv18.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/Online%20multi-object%20tracking%20with%20dual%20matching%20attention%20networks%201902.00749%20eccv18.pdf">[notes]</a>&nbsp;</p>
</li>
<li>
<p><strong>FAMNet Joint Learning of Feature, Affinity and Multi-Dimensional Assignment for Online Multiple Object Tracking</strong>&nbsp;[iccv19]&nbsp;<a href="1/FAMNet%20Joint%20Learning%20of%20Feature,%20Affinity%20and%20Multi-Dimensional%20Assignment%20for%20Online%20Multiple%20Object%20Tracking%20iccv19.pdf">[pdf]</a>&nbsp;<a href="1/FAMNet%20Joint%20Learning%20of%20Feature,%20Affinity%20and%20Multi-Dimensional%20Assignment%20for%20Online%20Multiple%20Object%20Tracking%20iccv19.pdf">[notes]</a></p>
</li>
<li>
<p><strong>Exploit the Connectivity: Multi-Object Tracking with TrackletNet</strong>&nbsp;[ax1811/mm19]&nbsp;<a href="1/Exploit%20the%20Connectivity%20Multi-Object%20Tracking%20with%20TrackletNet%20ax1811.07258%20mm19.pdf">[pdf]</a>&nbsp;<a href="1/Exploit%20the%20Connectivity%20Multi-Object%20Tracking%20with%20TrackletNet%20ax1811.07258%20mm19.pdf">[notes]</a></p>
</li>
<li>
<p><strong>Tracking without bells and whistles</strong>&nbsp;[ax1903/iccv19]&nbsp;<a href="1/Tracking%20without%20bells%20and%20whistles%20ax1903.05625%20iccv19.pdf">[pdf]</a>&nbsp;<a href="1/Tracking%20without%20bells%20and%20whistles%20ax1903.05625%20iccv19.pdf">[notes]</a>&nbsp;&nbsp;[pytorch]</p>
</li>

<li><strong>Tracking The Untrackable: Learning To Track Multiple Cues with Long-Term Dependencies</strong>&nbsp;[ax1704/iccv17] [Stanford]&nbsp;<a href="1/Tracking%20The%20Untrackable%20Learning%20To%20Track%20Multiple%20Cues%20with%20Long-Term%20Dependencies%20ax17_4_iccv17.pdf">[pdf]</a>&nbsp;<a href="1/Tracking_The_Untrackable_Learning_To_Track_Multiple_Cues_with_Long-Term_Dependencies.pdf">[notes]</a>&nbsp;&nbsp;,</li>
<li><strong>Multi-object Tracking with Neural Gating Using Bilinear LSTM</strong>&nbsp;[eccv18]&nbsp;<a href="1/Multi-object%20Tracking%20with%20Neural%20Gating%20Using%20Bilinear%20LSTM_eccv18.pdf">[pdf]</a>&nbsp;<a href="1/Multi-object%20Tracking%20with%20Neural%20Gating%20Using%20Bilinear%20LSTM_eccv18.pdf">[notes]</a></li>
<li><strong>Eliminating Exposure Bias and Metric Mismatch in Multiple Object Tracking</strong>&nbsp;[cvpr19]&nbsp;<a href="1/Eliminating%20Exposure%20Bias%20and%20Metric%20Mismatch%20in%20Multiple%20Object%20Tracking%20cvpr19.pdf">[pdf]</a>&nbsp;<a href="1/Eliminating%20Exposure%20Bias%20and%20Metric%20Mismatch%20in%20Multiple%20Object%20Tracking%20cvpr19.pdf">[notes]</a>&nbsp;</li>

<li><strong>Unsupervised Person Re-identification by Deep Learning Tracklet Association</strong>&nbsp;[ax1809/eccv18]&nbsp;<a href="1/Unsupervised%20Person%20Re-identification%20by%20Deep%20Learning%20Tracklet%20Association%201809.02874%20eccv18.pdf">[pdf]</a>&nbsp;<a href="1/Unsupervised%20Person%20Re-identification%20by%20Deep%20Learning%20Tracklet%20Association%201809.02874%20eccv18.pdf">[notes]</a></li>
<li><strong>Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers</strong>&nbsp;[ax1809/cvpr19]&nbsp;<a href="1/Tracking%20by%20Animation%20Unsupervised%20Learning%20of%20Multi-Object%20Attentive%20Trackers%20cvpr19%20ax1809.03137.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/Tracking%20by%20Animation%20Unsupervised%20Learning%20of%20Multi-Object%20Attentive%20Trackers%20cvpr19%20ax1809.03137.pdf">[notes]</a>&nbsp;</li>
<li><strong>Simple Unsupervised Multi-Object Tracking</strong>&nbsp;[ax2006]&nbsp;<a href="1/Simple%20Unsupervised%20Multi-Object%20Tracking%202006.02609.pdf">[pdf]</a>&nbsp;<a href="1/Simple%20Unsupervised%20Multi-Object%20Tracking%202006.02609.pdf">[notes]</a></li>

<li><strong>Learning to Track: Online Multi-object Tracking by Decision Making</strong>&nbsp;[iccv15] [Stanford]&nbsp;<a href="1/Learning%20to%20Track%20Online%20Multi-object%20Tracking%20by%20Decision%20Making%20%20iccv15.pdf">[pdf]</a>&nbsp;<a href="1/Learning_to_Track_Online_Multi-object_Tracking_by_Decision_Making__iccv15.pdf">[notes]</a>&nbsp;&nbsp;</li>
<li><strong>Collaborative Deep Reinforcement Learning for Multi-Object Tracking</strong>&nbsp;[eccv18]&nbsp;<a href="1/Collaborative%20Deep%20Reinforcement%20Learning%20for%20Multi-Object%20Tracking_eccv18.pdf">[pdf]</a>&nbsp;<a href="1/Collaborative%20Deep%20Reinforcement%20Learning%20for%20Multi-Object%20Tracking_eccv18.pdf">[notes]</a></li>

<li><strong>Near-Online Multi-target Tracking with Aggregated Local Flow Descriptor</strong>&nbsp;[iccv15] [NEC Labs]&nbsp;<a href="1/Near-online%20multi-target%20tracking%20with%20aggregated%20local%20%EF%AC%82ow%20descriptor%20iccv15.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/NOMT.pdf">[notes]</a></li>
<li><strong>Deep Network Flow for Multi-Object Tracking</strong>&nbsp;[cvpr17] [NEC Labs]&nbsp;<a href="1/Deep%20Network%20Flow%20for%20Multi-Object%20Tracking%20cvpr17.pdf">[pdf]</a>&nbsp;<a href="1/Deep%20Network%20Flow%20for%20Multi-Object%20Tracking%20cvpr17_supplemental.pdf">[supplementary]</a>&nbsp;<a href="1/Deep%20Network%20Flow%20for%20Multi-Object%20Tracking%20cvpr17.pdf">[notes]</a></li>

<li><strong>A Multi-cut Formulation for Joint Segmentation and Tracking of Multiple Objects</strong>&nbsp;[ax1607] [highest MT on MOT2015] [University of Freiburg, Germany]&nbsp;<a href="1/A%20Multi-cut%20Formulation%20for%20Joint%20Segmentation%20and%20Tracking%20of%20Multiple%20Objects%20ax16_9%20%5Bbest%20MT%20on%20MOT15%5D.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/A_Multi-cut_Formulation_for_Joint_Segmentation_and_Tracking_of_Multiple_Objects.pdf">[notes]</a></li>

<li><strong>Simple Online and Realtime Tracking</strong>&nbsp;[icip16]&nbsp;<a href="1/Simple%20Online%20and%20Realtime%20Tracking%20ax1707%20icip16.pdf">[pdf]</a>&nbsp;<a href="1/Simple%20Online%20and%20Realtime%20Tracking%20ax1707%20icip16.pdf">[notes]</a>&nbsp;</li>
<li><strong>High-Speed Tracking-by-Detection Without Using Image Information</strong>&nbsp;[avss17]&nbsp;<a href="1/High-Speed%20Tracking-by-Detection%20Without%20Using%20Image%20Information%20avss17.pdf">[pdf]</a>&nbsp;<a href="1/High-Speed%20Tracking-by-Detection%20Without%20Using%20Image%20Information%20avss17.pdf">[notes]</a>&nbsp;</li>

<li><strong>Deep Reinforcement Learning for Visual Object Tracking in Videos</strong>&nbsp;[ax1704] [USC-Santa Barbara, Samsung Research]&nbsp;<a href="1/Deep%20Reinforcement%20Learning%20for%20Visual%20Object%20Tracking%20in%20Videos%20ax17_4.pdf">[pdf]</a>&nbsp;&nbsp;&nbsp;<a href="1/Deep_Reinforcement_Learning_for_Visual_Object_Tracking_in_Videos.pdf">[notes]</a></li>
<li><strong>Visual Tracking by Reinforced Decision Making</strong>&nbsp;[ax1702] [Seoul National University, Chung-Ang University]&nbsp;<a href="1/Visual%20Tracking%20by%20Reinforced%20Decision%20Making%20ax17_2.pdf">[pdf]</a>&nbsp;&nbsp;&nbsp;<a href="1/Visual_Tracking_by_Reinforced_Decision_Making_ax17.pdf">[notes]</a></li>
<li><strong>Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning</strong>&nbsp;[cvpr17] [Seoul National University]&nbsp;<a href="1/Action-Decision%20Networks%20for%20Visual%20Tracking%20with%20Deep%20Reinforcement%20Learning%20%20cvpr17%20supplementary.pdf">[pdf]</a>&nbsp;<a href="1/Action-Decision%20Networks%20for%20Visual%20Tracking%20with%20Deep%20Reinforcement%20Learning%20%20cvpr17.pdf">[supplementary]</a>&nbsp;&nbsp;<a href="1/Action-Decision_Networks_for_Visual_Tracking_with_Deep_Reinforcement_Learning_cvpr17.pdf">[notes]</a>&nbsp;</li>
<li><strong>End-to-end Active Object Tracking via Reinforcement Learning</strong>&nbsp;[ax1705] [Peking University, Tencent AI Lab]&nbsp;<a href="1/End-to-end%20Active%20Object%20Tracking%20via%20Reinforcement%20Learning%20ax17_5.pdf">[pdf]</a>&nbsp;</li>

<li><strong>Fully-Convolutional Siamese Networks for Object Tracking</strong>&nbsp;[eccv16]&nbsp;<a href="1/Fully-Convolutional%20Siamese%20Networks%20for%20Object%20Tracking%20eccv16_9.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/SiameseFC.pdf">[notes]</a></li>
<li><strong>High Performance Visual Tracking with Siamese Region Proposal Network</strong>&nbsp;[cvpr18]&nbsp;<a href="1/High%20Performance%20Visual%20Tracking%20with%20Siamese%20Region%20Proposal%20Network_cvpr18.pdf">[pdf]</a>&nbsp;&nbsp;<a href="1/High%20Performance%20Visual%20Tracking%20with%20Siamese%20Region%20Proposal%20Network_cvpr18.pdf">[notes]</a></li>
<li><strong>Siam R-CNN Visual Tracking by Re-Detection</strong>&nbsp;[cvpr20]&nbsp;<a href="1/Siam%20R-CNN%20Visual%20Tracking%20by%20Re-Detection%201911.12836%20cvpr20.pdf">[pdf]</a>&nbsp;<a href="1/Siam%20R-CNN%20Visual%20Tracking%20by%20Re-Detection%201911.12836%20cvpr20.pdf">[notes]</a>&nbsp;&nbsp;</li>

<li><strong>ATOM Accurate Tracking by Overlap Maximization</strong>&nbsp;[cvpr19]&nbsp;<a href="1/ATOM%20Accurate%20Tracking%20by%20Overlap%20Maximization%20ax1811.07628%20cvpr19.pdf">[pdf]</a>&nbsp;<a href="1/ATOM%20Accurate%20Tracking%20by%20Overlap%20Maximization%20ax1811.07628%20cvpr19.pdf">[notes]</a>&nbsp;</li>
<li><strong>DiMP Learning Discriminative Model Prediction for Tracking</strong>&nbsp;[iccv19]&nbsp;<a href="1/DiMP%20Learning%20Discriminative%20Model%20Prediction%20for%20Tracking%20ax1904.07220%20iccv19.pdf">[pdf]</a>&nbsp;<a href="1/DiMP%20Learning%20Discriminative%20Model%20Prediction%20for%20Tracking%20ax1904.07220%20iccv19.pdf">[notes]</a>&nbsp;</li>
<li><strong>D3S &ndash; A Discriminative Single Shot Segmentation Tracker</strong>&nbsp;[cvpr20]&nbsp;<a href="1/D3S%20%E2%80%93%20A%20Discriminative%20Single%20Shot%20Segmentation%20Tracker%201911.08862v1%20cvpr20.pdf">[pdf]</a>&nbsp;<a href="1/D3S%20%E2%80%93%20A%20Discriminative%20Single%20Shot%20Segmentation%20Tracker%201911.08862v1%20cvpr20.pdf">[notes]</a>&nbsp;</li>

<li><strong>Bridging the Gap Between Detection and Tracking A Unified Approach</strong>&nbsp;[iccv19]&nbsp;<a href="1/Bridging%20the%20Gap%20Between%20Detection%20and%20Tracking%20A%20Unified%20Approach%20iccv19.pdf">[pdf]</a>&nbsp;<a href="1/Bridging%20the%20Gap%20Between%20Detection%20and%20Tracking%20A%20Unified%20Approach%20iccv19.pdf">[notes]</a></li>

<li><strong>Do Deep Nets Really Need to be Deep</strong>&nbsp;[nips14]&nbsp;<a href="1/Do%20Deep%20Nets%20Really%20Need%20to%20be%20Deep%20ax1410%20nips14.pdf">[pdf]</a>&nbsp;<a href="1/Do%20Deep%20Nets%20Really%20Need%20to%20be%20Deep%20ax1410%20nips14.pdf">[notes]</a></li>

<li><strong>Decoupled Neural Interfaces using Synthetic Gradients</strong>&nbsp;[ax1608]&nbsp;<a href="1/Decoupled%20Neural%20Interfaces%20using%20Synthetic%20Gradients%20ax1608.05343.pdf">[pdf]</a>&nbsp;<a href="1/Decoupled%20Neural%20Interfaces%20using%20Synthetic%20Gradients%20ax1608.05343.pdf">[notes]</a></li>
<li><strong>Understanding Synthetic Gradients and Decoupled Neural Interfaces</strong>&nbsp;[ax1703]&nbsp;<a href="1/Understanding%20Synthetic%20Gradients%20and%20Decoupled%20Neural%20Interfaces%20ax1703.00522.pdf">[pdf]</a>&nbsp;<a href="1/Understanding%20Synthetic%20Gradients%20and%20Decoupled%20Neural%20Interfaces%20ax1703.00522.pdf">[notes]</a></li>

<li><strong>EfficientNet:Rethinking Model Scaling for Convolutional Neural Networks</strong>&nbsp;[icml2019]&nbsp;<a href="1/EfficientNet_Rethinking%20model%20scaling%20for%20CNNs.pdf">[pdf]</a>&nbsp;<a href="1/EfficientNet_%20Rethinking%20Model%20Scaling%20for%20Convolutional%20Neural%20Networks.pdf">[notes]</a></li>

<li><strong>Learning Features by Watching Objects Move</strong>&nbsp;(cvpr17)&nbsp;<a href="1/Learning%20Features%20by%20Watching%20Objects%20Move%20ax170412%20cvpr17.pdf">[pdf]</a>&nbsp;<a href="1/Learning%20Features%20by%20Watching%20Objects%20Move%20ax170412%20cvpr17.pdf">[notes]</a></li>

<li><strong>Video Frame Interpolation via Adaptive Convolution</strong>&nbsp;[cvpr17 / iccv17]&nbsp;<a href="1/Video%20Frame%20Interpolation%20via%20Adaptive%20Convolution%20ax1703.pdf">[pdf (cvpr17)]</a>&nbsp;<a href="1/Video%20Frame%20Interpolation%20via%20Adaptive%20Separable%20Convolution%20iccv17.pdf">[pdf (iccv17)]</a>&nbsp;<a href="1/Video%20Frame%20Interpolation%20via%20Adaptive%20Convolution%20ax1703.pdf">[ppt]</a></li>

<li><strong>beta-VAE Learning Basic Visual Concepts with a Constrained Variational Framework</strong>&nbsp;[iclr17]&nbsp;<a href="1/beta-VAE%20Learning%20Basic%20Visual%20Concepts%20with%20a%20Constrained%20Variational%20Framework%20iclr17.pdf">[pdf]</a>&nbsp;<a href="1/beta-VAE%20Learning%20Basic%20Visual%20Concepts%20with%20a%20Constrained%20Variational%20Framework%20iclr17.pdf">[notes]</a></li>
<li><strong>Disentangling by Factorising</strong>&nbsp;[ax1806]&nbsp;<a href="1/Disentangling%20by%20Factorising%20ax1806.pdf">[pdf]</a>&nbsp;<a href="1/Disentangling%20by%20Factorising%20ax1806.pdf">[notes]</a></li>
</ul>
